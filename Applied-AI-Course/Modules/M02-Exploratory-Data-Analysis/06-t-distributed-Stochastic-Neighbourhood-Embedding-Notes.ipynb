{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce5a64c",
   "metadata": {},
   "source": [
    "Link: https://youtu.be/NEaUSP4YerM\n",
    "\n",
    "Link: https://youtu.be/wvsE8jm1GzE\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/159163250-04002035-fedb-4f55-bee8-f02eaa42584e.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/159163341-4eedb460-0992-4ae5-9928-270d10e3303f.png)\n",
    "\n",
    "Global structure means preserving the global shape between all the datapoints like in Principal Component Analysis that are great at retaining global structure, because it looks at ways in which a datasetâ€™s variance is retained, globally, across the entire dataset.\n",
    "\n",
    "In other words local approaches seek to map nearby points on the manifold to nearby points in the low-dimensional representation. Global approaches on the other hand attempt to preserve geometry at all scales, i.e mapping nearby points to nearby points and far away points to far away points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c90da",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117f9fb6",
   "metadata": {},
   "source": [
    "__Neighbourhood__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/159163915-e253f319-3688-4e0b-867a-b78cec5023d9.png)\n",
    "\n",
    "__Embedding__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/159164140-e4e83c91-28fb-4a1c-a380-75ca3813fd73.png)\n",
    "\n",
    "Let us assume we have dataset of 'N' data points and each point is d-dimensional. So now if we embed the points into 3-D form (say). Then the physical existence of the points will be the same, but the axes will be rotated in such a way that for every datapoint on an axes, its neighborhood is preserved.\n",
    "\n",
    "For example we have 1000-dimensional dataset and we need to reduce it to 3D form. So all the axes here are rotated in the direction where each data point has __maximum of its neighborhood preserved__. The top 3 axes with maximum neighborhood preserved are chosen and in order to get the new coordinates of these points, we need to draw projections of each of these points onto these 3 newly formed axes and this way we could find out the new coordinates of each point.\n",
    "\n",
    "On the basis of the geometrical distance, the neighborhood is preserved. In T-SNE, when we wanted to reduce the dimensionality of the given data, the data is transformed from a higher dimensional space to a lower dimensional space in such a way that majority of the points in the neighborhood in higher dimensional space occur similarly in the neighborhood in lower dimensional space and this neighborhood is on the basis of geometrical distance between the points.\n",
    "\n",
    "The intuition is that close neighborhood from high dimension is also maintained in low dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e306ddb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de74d7",
   "metadata": {},
   "source": [
    "__Geometric Intuition of t-SNE__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/159165088-b5bc94fb-edfe-40dd-a4bb-7ad8844f5301.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a260e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b163eeb",
   "metadata": {},
   "source": [
    "__Crowding Problem__\n",
    "\n",
    "Sometimes, it is impossible to preserve distances in all the neighbourhoods. This case is called as Crowding Problem.\n",
    "\n",
    "Neighbourhood has to be preserved for all the points.\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/159166368-6bda3237-0bab-44fc-b5e1-0bba50a5936f.png)\n",
    "\n",
    "Link: https://youtu.be/ylx_1bsnv2c?list=PLupD_xFct8mHqCkuaXmeXhe0ajNDu0mhZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3adfa6c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ccef31",
   "metadata": {},
   "source": [
    "__Why t-Distribution?__\n",
    "\n",
    "- Here, we are using t-distribution because it explains the more variance better than any other plot as it has got more tail region. More tail region means more variance/density.\n",
    "- Finally while embedding, we need the better distance/variance explained from one point to the rest of the points. It can be easily done with t-distribution.\n",
    "\n",
    "![](https://i.imgur.com/ae9GQKC.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e80dd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a02ef3",
   "metadata": {},
   "source": [
    "__How to apply t-SNE and interpret its output?__\n",
    "\n",
    "Link: https://distill.pub/2016/misread-tsne/\n",
    "\n",
    "t-SNE is an iterative and probabilistic algorithm. The more the number of iterations, the better the outcome. The final outcome reaches a stable structure where no data-point is moving.\n",
    "\n",
    "Two important parameters: Steps and Perplexity.\n",
    "\n",
    "- Steps: Number of iterations. At each iteration, we are trying to change the embedding points slightly in such a way that the newly embedded points better preserve the neighborhood than the previous configuration by solving an optimization problem.\n",
    "- Perplexity: Loosely number of neighbours to whom the distances has to be preserved.\n",
    "    - Keep the perplexity less than the number of data-points.\n",
    "\n",
    "Limitations\n",
    "\n",
    "- t-SNE expands the dense clusters and shrinks the sparse cluster and in the end we have same density for the clusters. We cannot say anything about the cluster sizes.\n",
    "- t-SNE does not preserve the distances between clusters.\n",
    "\n",
    "Lessos:\n",
    "\n",
    "1. Never run t-SNE just once.\n",
    "2. Run for different iterations till the shapes stabilize.\n",
    "3. Run for different perplexity values $2 \\le p <n $.\n",
    "4. Re-run the t-SNE for same perplexity and iterations and see whether the output is stable or not.\n",
    "\n",
    "Epsilon is a optimization parameter. Basically tells us how fast should the algorithm reaches the stable shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7cc238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bdbe4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
