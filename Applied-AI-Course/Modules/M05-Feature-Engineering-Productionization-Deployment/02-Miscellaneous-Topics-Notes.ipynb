{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e45322d",
   "metadata": {},
   "source": [
    "__Calibration of Models: Need for Calibration__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176053849-500b44b2-a1ca-4f8d-b77f-a5181e328f2d.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176054099-ba05f159-b820-4e8c-a684-219a9aa4e300.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176054779-6c2c601d-0ee8-4893-9f7d-2d119e41493e.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176055949-ca4cef81-e532-4560-b607-8a92275ab358.png)\n",
    "\n",
    "The main idea is that, as the prediction probability is near to the actual probability value then we will say that it is well calibrated model.\n",
    "\n",
    "The probability that is given by any model is called predicted probability value.\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176058968-60ee096c-b54b-43d3-96df-dc6e0c2840a9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcce574",
   "metadata": {},
   "source": [
    "__Calibration Plots__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176059390-ae16cc2f-e92c-404c-b314-60fc583d565b.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176059579-a3d5e6c6-2d32-40ef-90ce-91fcd829a352.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176059737-ca1b8984-711d-4998-ac90-f403f57bf2c5.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176060097-dedfcaed-cfbe-405b-8d39-7eadea554f0e.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176060303-d264cf17-6818-4193-a4c0-e04c94a07956.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176060567-81351505-6838-41d1-a014-7156193575eb.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176061833-22379e3a-c46a-42d4-911d-cab117dd3ce1.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176587729-8c2bf1fa-0471-46e0-a2ac-946f0365da14.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176061959-597bd926-fb09-4e97-ad05-5c019aa8b3bb.png)\n",
    "\n",
    "Link: https://scikit-learn.org/stable/modules/calibration.html\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_compare_calibration_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e023f915",
   "metadata": {},
   "source": [
    "__Plattâ€™s Calibration/Scaling__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176586566-7461ef86-dcb7-451d-8aee-3d25f5c3be12.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176587010-bb28179f-b4f8-4b7c-8097-0bc5a10308f6.png)\n",
    "\n",
    "Platt scaling works iff the calibration data looks like sigmoidal function. Otherwise, in such cases, we opt the method of Isotonic calibration or Isotonic regression.\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176587266-d6019722-f835-476b-abb3-ddf491cb0630.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176587913-78d1f7d1-440d-46c6-a2e0-730488bff88f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19d9a0d",
   "metadata": {},
   "source": [
    "__Isotonic Regression__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176792470-29c29446-3532-42ae-8e6d-98024d051022.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176792920-35f2017d-104e-4b2e-8536-9124ae5ec58c.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176793116-b46e4f59-9f68-45c9-83da-4c6eb126c815.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176793363-e948ce61-c066-48a9-b11d-e8a5abe285f0.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176793973-592e00fb-68c1-40b7-8e49-afb054aa2386.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176794278-403788a1-d8a4-48fd-a6d2-84c19522dd4b.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176796241-85a11ba5-52f4-4523-810c-790fea54259c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61083d6f",
   "metadata": {},
   "source": [
    "__Modeling in the presence of outliers: RANSAC__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176800018-2ce0e736-ed9d-4330-a4c9-87b10caa10e6.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176800284-1769889c-9ee9-4e56-a058-3c93ceaf330c.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176800460-c831059f-3021-4007-95eb-7f06e2ae8180.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176800683-283bfc54-c413-49c7-b199-47ef11984ff5.png)\n",
    "\n",
    "Link: https://soundcloud.com/applied-ai-course/ransac-vs-regularization\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176801402-2d52ed90-ac01-400b-b2bf-314366f35861.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d887b9",
   "metadata": {},
   "source": [
    "__Retraining Models Periodically__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176988518-6b4b3e3c-284f-43c6-b39e-6232a0f10e34.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176988610-f3b85019-252e-4947-95a7-3bc81f98621d.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176988807-5f57fb87-e012-442a-805a-533ef63768af.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5b30aa",
   "metadata": {},
   "source": [
    "__A/B Testing__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176990667-cd8b8c0e-7479-4763-b948-1d050ac8ed09.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176990726-4b16284d-0a7b-47c1-ad28-1c6a1f26bd64.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176990818-0233bf73-ebec-4033-b9b9-c8be5bf5bf21.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176990855-c9724311-12d4-4ba1-b21a-7b29850aabf1.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176990941-a0d9a4cc-7671-4951-bf93-7e8028edac99.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176990999-be1c9829-c6dd-43af-b94a-fb2196d415f4.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176991057-448a76ef-5719-4136-adc3-29b6378b2dae.png)\n",
    "\n",
    "If CIs of A and B are not overlapping, then we can say that model B is almost better as model A.\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176991122-fa5468ab-923f-4bc9-b0b1-a910b812f93a.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176991372-1dd863ee-9731-430b-8da2-71359c83633b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc94dec",
   "metadata": {},
   "source": [
    "__VC Dimension__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176992779-8f098b93-6209-4b49-b49e-8e9de8e7430b.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176992892-4f3172e8-441f-41ba-a1fc-ea8b2e93d340.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176993004-7d30eef4-ec16-4f5f-bf0c-9acdbce923e0.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176993089-70afabdf-5191-441f-9a74-03b4e9128155.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176993225-bc249e1f-65ba-40e5-92e4-3dfdb28f7a53.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/176993354-978561c8-9fff-405d-a0a9-c23b9f197f43.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60cc48e",
   "metadata": {},
   "source": [
    "__Data Science Life Cycle__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/180899200-6beb1259-d0ef-4349-85e6-a7d2a13fe937.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/180899765-954c011f-3bc2-47e2-9da9-797b9d68d400.png)\n",
    "\n",
    "Data life cycle is similar to SDLC in software development.Data life cycle must be followed to make an effective ML project.There are 11 general steps which are described below:-\n",
    "\n",
    "Steps:-\n",
    "\n",
    "1) Understanding business requirements:- It includes gathering information about the problem from the users and define the problem what is it.Sometimes it can become very tedious as we have to be very careful while gathering the information about the project.\n",
    "\n",
    "2) Data acquisition:- It includes ETL(Extracts Transforms Loads) and most pouplar tool used for this step is SQL(DB,DW,log-files,Hadoop/Spark).Basically this is the step in which we understand where the data is stored and then obatins or loads the data which we required from various sources or files by using mainly sql.\n",
    "\n",
    "3) Data preparation:- Now in this step we will have all the data we need whoch we have acquired from the previous step.Now our work is to clean and pre-pocessed the data,so that it can be made useful for making nay ML algo work.Form e.g removing any special character from the text data if any present,handling missing values or NaN values,standardization,featurization.For this we first try to figure what the data is by applying various libraries and tries to print the data and check if there is any incorrect data or the points which is not useful in our model and then after detecting we removes those points or clean the text data.\n",
    "\n",
    "4) Exploratory Data Analysis(EDA):-  In  this data visualization is done by using various plots.Most commonly used plots are scatter plots,box plot ,heat map,violon plot,bar plot,contour plot,line plot,pdf,cdf,histogram,geo-map,pair-plots,Q-Q plots,t-SNE etc.Basocally by doing we try figure out what are the features that are important and understand the content of the data more accurately and what trend it is following.\n",
    "\n",
    "5) Modeling,Evaluation & Interpretation:- This is the step where we actually apply various ML algorithms like LR,NB,SVM etc and form the model by evaluating on datasets like D_train,D_CV,D_test and tuning hyperparamter to avoid overfitting or underfittig.Applying any model is not easy,first we have to understand that what are algos which will be perfect for the problem and dataset,and then identifying the right performnace metric is aso an imprtant task in modeling.So we have to try the ML algos with different metrics and try to figure out which one is doing best.\n",
    "\n",
    "6) Communicate results:Clean & simple:- After making the model this step include communicating the results with the stakeholders or users or executives for which we are making this model.The results should be very clean and understandable,because there can be case where persons like users may not know machine learning.This is also one of the very important steps as it includes convicing tyhe manager/users by communicating the results,if this step fails then all the hardwork of making nodel will go in vain,even if you have made the good project but bad communication can fail your success.\n",
    "\n",
    "7) Deployment:-  Once we got the approval from the previos step,now it's time the deploy the model which is s software engineering effort.It can be employed sometimes by machine learning engineer or by sofware engineer.\n",
    "\n",
    "8) real world testing-A/B testing:- In this step the model is tested in the real world environment by using A/B testing.Bascially this is the process where we test our model on real world and get the results which will be helpful in the next step.\n",
    "\n",
    "9) Customer buy-in:- In this step we try to convince the user in our model by showing the results of the model on real world environment which we have obtained in the previous step.\n",
    "\n",
    "10) Operations-retrain models,handle failures,process:- This includes identifying that when,how to retrain the models from time to time which  we have deployed already in tyhe real world.And if any failure cases occur in the future and handling that case is also includes in this step.\n",
    "\n",
    "11) Optimization-improve models,more data,more features,optimize code:- This is the last step in which we can add more data,more features and improving the models according to the requirement.This is the step which we need to keep doing from time to time according to the requirements and trend in the real world.\n",
    "\n",
    "Note: \n",
    "\n",
    "1) The amount of time given to each step depends on project to project or from company to company.\n",
    "\n",
    "2) In some cases we need not to follow all the steps,but yes these are general steps for any model which we should keep in mind while creating any model or ML project.There can be many individual persons which can be involved for achieving these steps.Assigning different steps can be done in this process or one individual can follow all the steps alone if he/she experienced enough like a data scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176ca37c",
   "metadata": {},
   "source": [
    "__Productionization and Deployment of Machine Learning Models__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/180902654-4673eb4d-7fa2-49e8-bd8b-d2abf656f3ce.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/180900961-68f57172-40d6-4142-8278-b1d95eb7bd2b.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/180901555-d364cc90-869e-4377-9636-5ffe225d9e27.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/180901839-14589967-3f1b-40a8-a812-67f9a51264e2.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/180902004-c4aa61dc-bf31-4037-9723-543a7d7e7421.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/180902174-95cc7d30-a232-400e-940a-029b85c277bc.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/180902430-93c8530b-d68c-403d-a0af-2d6f0bbae705.png)\n",
    "\n",
    "Link: https://soundcloud.com/applied-ai-course/are-cloud-based-ml-tools-a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f5d31e",
   "metadata": {},
   "source": [
    "Productionization and deployment: https://youtu.be/wF_sB_OnCfk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e38a6",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/63338657/188298481-f0a87679-c4a6-4dd5-a82e-9b7a2eb6bded.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b3bb0e",
   "metadata": {},
   "source": [
    "SelectKBest: https://youtu.be/UW9U0bYJ-Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613e09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3830776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506095f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc14d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4daedd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d6906d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9612aac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
