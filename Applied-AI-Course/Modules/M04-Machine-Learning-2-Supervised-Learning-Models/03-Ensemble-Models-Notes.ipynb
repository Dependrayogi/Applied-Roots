{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eddec35",
   "metadata": {},
   "source": [
    "__What are ensembles?__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172960440-ee6b7de0-10bb-44b9-b1eb-8c6a2cdab7ed.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172960699-9a3b29e8-e18d-4122-9b96-87065516967e.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172960900-ca09f3f0-8d2d-4e2c-9b42-c5f45ac0a285.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb2623",
   "metadata": {},
   "source": [
    "__Bootstrapped Aggregation (Bagging) Intuition__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172962116-970dcd65-f122-4412-a4fe-4a217d71c6de.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172962275-90c57c88-f560-4d2f-a9e4-f5f33860b80f.png)\n",
    "\n",
    "For classification - majority vote.\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172962508-2cc2876a-1257-4525-ba4f-5127922857f3.png)\n",
    "\n",
    "For regression: mean or median.\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172962683-6989b05d-2820-45d8-9cfb-d694f116f074.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172963002-ed6abe42-ba79-4b85-9a1b-b7e55b362f28.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172963764-e42086a4-0a62-4f2d-b3ec-63c1d08a92f6.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172963914-1d093cc8-2346-4cc6-9f90-e1320c6889bb.png)\n",
    "\n",
    "1. Training a single overfit model would trivially lead us to an overfit model.\n",
    "2. Training many overfit models on the same data and then aggregating would not help as each of these models are the same as they are trained on the same data. This would also lead to an overall overfit model.\n",
    "3. Training each model on a sample of data with each of these models being overfitted and then aggregating would reduce the overfit in each of the base models and result in an overall better model.\n",
    "\n",
    "Note that, bagging ONLY works if each of the base-models is slightly different from each other and overfit and hence we build each of the base models on a sample of data and not complete data.\n",
    "\n",
    "Bias^2 + Variance + Irreducible Error = Test Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d3d8db",
   "metadata": {},
   "source": [
    "__Random Forest and their construction__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172967183-d668a647-075a-4383-8f2a-a4d44b14085b.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172967393-ae198e1f-dd59-4aec-852d-fb086d48a001.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172967680-d2d67633-61f4-4f9d-8c52-2b9bb062d820.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172967879-27c2a92c-d210-4ee0-bcf4-1921fd23f068.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172968177-b4345ca9-b90b-4471-9586-e1da9221c372.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172968254-c8141068-24f0-4bbf-84e3-b96f2bdefd3e.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/172968463-892a3a59-fe33-4fdb-840e-c4f57c859e4d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c8eb2b",
   "metadata": {},
   "source": [
    "__Bias-Variance Tradeoff__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173219716-835b26a5-f843-4bfa-b2ec-4a4c13811bea.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173219796-628121f5-6041-408f-b54d-f5e566d59386.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173220052-54cc2f7c-bf52-42e5-ab3f-6beaff0d5cd1.png)\n",
    "\n",
    "Low CSR and RSR will reduce the variance of the overall model. The base learners have high variance because we allow them to grow deeper. If CSR = 0 and RSR = 0 then all the base learners learn the same thing and the aggregation of such base models is equivalent to a single base model, in this case, the variance of the aggregation is equal to the variance of the base model that is high variance.\n",
    "\n",
    "If we take very large k without hyperparameter tuning then it reduces variance largely there by final model underfits.\n",
    "\n",
    "The ultimate goal of Bagging is to reduce the variance keeping the bias constant.\n",
    "\n",
    "Case 1:\n",
    "\n",
    "If we build Bagging model with perfect base learners(optimal variance and optimal bias), then the resultant model will have same bias and the variance still decreases.\n",
    "\n",
    "Case 2:\n",
    "\n",
    "If we build Bagging model with high bias and low variance models, then the variance of the resultant model still decreases further and become almost zero. (the model underfits more)\n",
    "\n",
    "Hence it is recommended to build Bagging model only using High Variance and Low Bias Base learners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c355e83b",
   "metadata": {},
   "source": [
    "__Bagging Train and Runtime complexity__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173220865-7c6f33e4-f993-4592-9f38-6831a1bf96ef.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173220954-8fa380eb-002e-4e6a-ba2f-60ec325a2c7a.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173221053-d5c0a948-582f-4d00-aa95-ae48a70e3dac.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1eb84",
   "metadata": {},
   "source": [
    "__Extremely Randomized Trees__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173224449-811916e5-464b-413a-bc3e-a7502f04cf22.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173224575-3e1c23c5-2061-49d2-bc7c-e02e346872fb.png)\n",
    "\n",
    "In Random Forest models, we perform Row Sampling + Column Sampling + Aggregation.\n",
    "Whereas in Extremely randomized trees, we perform  Row Sampling + Column Sampling + Aggregation + Randomization in selecting T(tau).\n",
    "In case of Random Forest models, we are reducing the variance while keeping the bias the same using a majority vote on the base learners built using column and row samplings.\n",
    "\n",
    "Whereas in extremely randomized trees, in addition to majority vote, we are also trying to reduce the variance further on each base learner by adding one more level of randomization in splitting the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f3b91c",
   "metadata": {},
   "source": [
    "__Random Forest: Cases__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173225029-94de16e4-7c3f-4e77-8fb4-6a21fc4408ec.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173225153-4455e53e-9eb5-43ea-8ee5-3b0880afed22.png)\n",
    "\n",
    "Link: https://youtu.be/nyxTdL_4Q-Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae0ca6",
   "metadata": {},
   "source": [
    "__Boosting Intuition__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173229689-2b3d3626-d798-44ed-aaae-e33d38c34d3a.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173229871-7a6dc8db-741f-4f00-84e8-3ccf68256676.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173230035-21869875-d923-4dae-b082-251f28ab620e.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173230129-ba93a10f-6d06-4169-9c18-cfc4d8f1ae50.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173230496-b6b9ebac-90f9-433a-b24d-694dd01ed0a5.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173230625-dd0a2f44-a591-44b1-bcfa-e8211dda9bec.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173230885-363f3d7a-9bdf-49cf-903b-10016a59b5a6.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173230928-9b87300c-38a5-4656-9b06-9bec7fa05a60.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6feb60f",
   "metadata": {},
   "source": [
    "__Residuals, Loss Functions and Gradients__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173625223-dba6a1fb-3aab-4b2b-a63b-13f5a5ec4f14.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173625897-786e3f8a-fe20-4f77-96bb-1c184aa6b26d.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173626973-01f65f0d-cba7-4242-82b1-b1bfc49e2bcc.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173628074-8e80dba6-1dbc-4b14-b2c7-1f492986a2e1.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173628517-09251e13-e39d-443c-aaf8-0f29b3d4eba8.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/173628956-1763882d-c659-45d5-a2ee-81a35a733a1d.png)\n",
    "\n",
    "Link: https://youtu.be/qEZvOS2caCg\n",
    "\n",
    "Link: https://youtu.be/1o0yd6eMmA0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b4b849",
   "metadata": {},
   "source": [
    "__Gradient Boosting__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174426442-78a6b92b-17d0-4b79-818e-ce3c7b177f0b.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174426496-4fd3f6f8-41ab-439a-b2cf-248e2da9fe7f.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174426571-85aa888b-0760-40ac-a9c1-9e103b9cc631.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174426610-9eac6149-5f2b-4126-8b37-d7d40cddc751.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174426651-01e6365f-376f-4ab5-9056-be9485d1565f.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174426768-27b9b77a-5d8e-45ba-a49c-5f704ba1b418.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174426813-7cd53f96-ba18-45fc-95cd-570e7788f249.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174426901-50617938-7ace-4502-8110-f425c5fb14fe.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174426928-49892995-e43e-4ff3-9746-9e780f3905a6.png)\n",
    "\n",
    "Link: https://explained.ai/gradient-boosting/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a158e8",
   "metadata": {},
   "source": [
    "__Regularization by Shrinkage__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174433159-965a1016-3636-4191-b5b8-fda1cf9e3cb6.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174433298-78aca667-b389-46ff-afde-08bf2b5f1b04.png)\n",
    "\n",
    "$M$ and $v$ are hyperparameters.\n",
    "\n",
    "Researchers who came up with boosting methods noticed that most boosting models were overfitting very quickly even with few base models. So they wanted to add another hyper-param so that we can have hundreds of base learners each learning some aspect of the data while not overfitting. So, they came up with $v$ as a shrinkage coefficient which ensures that we consider the earlier fitted models' outputs partially thereby avoiding overfitting. Many experimental results showed that having $v$ as a shrinkage parameter would improve overall performance. There are also theoretical arguments for benefits of shrinkage.\n",
    "\n",
    "There are no rules that we should have only one hyper-param to control overfitting. For example, in RBF-SVMs, we have both $C$ and $\\sigma$ which control overfitting. Similarly, in boosting, we have the number of base-learners and $v$ both controlling overfitting.\n",
    "\n",
    "Note that $v$ is a hyper-param and having different $v$'s will make the hyperparameter tuning more cumbersome and hard. Hence, in practice, we often fix the $v$ to a single value for all models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6760ea8",
   "metadata": {},
   "source": [
    "Before deployment, we train the model and check its performance on unseen data which has class labels, i.e., test dataset. In reality, models degrade over time due to reasons such as concept drifts. So, we keep training models and evaluate them as and when new data is available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db04d66",
   "metadata": {},
   "source": [
    "__Train and Runtime Complexity__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174435232-9f9d8538-46a5-43b3-84e6-7cd0bcd9da32.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174435304-5c670878-198b-4ad6-bdd3-248214c1a94c.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174435361-2bb241a1-e175-4d7a-8e77-b12b9df9a3ad.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174435482-0fabfc0e-5e25-41d3-b525-a75cda358311.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da739bc",
   "metadata": {},
   "source": [
    "__XGBoost: Boosting + Randomization__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174437547-1b282212-6614-487d-849b-0bb0d8aeaf44.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b8b224",
   "metadata": {},
   "source": [
    "__AdaBoost: Geometric Intuition__\n",
    "\n",
    "Link: https://alliance.seas.upenn.edu/~cis520/wiki/index.php?n=lectures.boosting\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174467587-9c18df65-3d44-4087-a5e6-75bf46f8eb44.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174467608-1b5a304a-d5e4-4c08-b1b7-22477860a418.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174467625-1264ff37-9eaa-49ec-8b01-8b6570563603.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174467672-cfdd8317-4b72-4968-8de9-5f46c37d4089.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174467933-756a29f1-9081-4692-94b4-6b4f99809587.png)\n",
    "\n",
    "AdaBoost is a popular boosting technique which helps you combine multiple “weak classifiers” into a single “strong classifier”. A weak classifier is simply a classifier that performs poorly, but performs better than random guessing.\n",
    "\n",
    "Link: https://mccormickml.com/2013/12/13/adaboost-tutorial/\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174468329-b014e609-d052-4e43-992c-617d942ef18a.png)\n",
    "\n",
    "Link: https://www.mygreatlearning.com/blog/adaboost-algorithm/\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174468413-cb2efd0c-112d-4de4-bc3d-9e806038eb8b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5446b51c",
   "metadata": {},
   "source": [
    "__Stacking Models__\n",
    "\n",
    "Link: http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174468615-2b7014a5-1227-4edd-bba8-bae6f8bc9893.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174468666-402ed4c9-5660-4996-8f03-707659012faf.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174468762-7fe451a0-5c23-4d0f-a27c-f425b8315a7d.png) \n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174468837-1cad96d5-a833-47e8-8570-c11fa76cec51.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174469026-6bb959a6-11fa-418d-8647-c9042deec770.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174469090-e24aaebf-b3db-4036-bd1d-92447097a552.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174469132-b306e68c-4578-46af-9fdc-da13b0f90a5f.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174469212-24ba9684-a3c1-4e71-9d26-54cded097dda.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174469315-82d2f816-1ef9-404b-b166-d04fb6baed37.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174469408-a8cf9e84-6e92-42f6-80b2-882a7bd78e41.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7179be70",
   "metadata": {},
   "source": [
    "__Cascading Classifiers__\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174472249-eb4d8002-017b-450b-a296-9c10badd5ee5.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174472318-0440fc9d-b796-44ba-84be-bf05f9b4c87c.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174472430-b21dd47d-085e-4bdf-a312-ae17f8252bab.png)\n",
    "\n",
    "![](https://user-images.githubusercontent.com/63338657/174472499-542a6cc8-9b17-4659-8ae4-b60596308f14.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f585907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
