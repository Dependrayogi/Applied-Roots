{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "168QPRizVFFg"
   },
   "source": [
    "<p style=\"font-size:32px;text-align:center\"> <b>Social network Graph Link Prediction - Facebook Challenge</b> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8lS7fVyVFFl"
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "# please do go through this python notebook: \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import csv\n",
    "import pandas as pd#pandas to create small dataframes \n",
    "import datetime #Convert to unix time\n",
    "import time #Convert to unix time\n",
    "# if numpy is not installed already : pip3 install numpy\n",
    "import numpy as np#Do aritmetic operations on arrays\n",
    "# matplotlib: used to plot graphs\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns#Plots\n",
    "from matplotlib import rcParams#Size of plots  \n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans#Clustering\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "# to install xgboost: pip3 install xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "import networkx as nx\n",
    "\\\n",
    "import pdb\n",
    "import pickle\n",
    "from pandas import HDFStore,DataFrame\n",
    "from pandas import read_hdf\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1znHayNeVFFt"
   },
   "source": [
    "# 1. Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uq9HbHwEVFFv",
    "outputId": "b2aa525a-93d3-47c3-8216-416a811bc812"
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('data/after_eda/train_pos_after_eda.csv'):\n",
    "    train_graph=nx.read_edgelist('data/after_eda/train_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "    print(nx.info(train_graph))\n",
    "else:\n",
    "    print(\"please run the FB_EDA.ipynb or download the files from drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmlUa64tVFF7"
   },
   "source": [
    "# 2. Similarity measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivVMUMiWVFF9"
   },
   "source": [
    "## 2.1 Jaccard Distance:\n",
    "http://www.statisticshowto.com/jaccard-index/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoWCYuRBVFF_"
   },
   "source": [
    "\\begin{equation}\n",
    "j = \\frac{|X\\cap Y|}{|X \\cup Y|} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Seo4z5SnVFGB"
   },
   "outputs": [],
   "source": [
    "#for followees\n",
    "def jaccard_for_followees(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
    "                                    (len(set(train_graph.successors(a)).union(set(train_graph.successors(b)))))\n",
    "    except:\n",
    "        return 0\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oa9FMlS8VFGF",
    "outputId": "e1fc3a04-7a56-4c60-826b-e2b254857b45"
   },
   "outputs": [],
   "source": [
    "#one test case\n",
    "print(jaccard_for_followees(273084,1505602))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gf8njOv6VFGK",
    "outputId": "f057ff43-89f6-4f9c-cd48-ac38272cab36"
   },
   "outputs": [],
   "source": [
    "#node 1635354 not in graph \n",
    "print(jaccard_for_followees(273084,1505602))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LO-a5ZkKVFGO"
   },
   "outputs": [],
   "source": [
    "#for followers\n",
    "def jaccard_for_followers(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.predecessors(a))) == 0  | len(set(g.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
    "                                 (len(set(train_graph.predecessors(a)).union(set(train_graph.predecessors(b)))))\n",
    "        return sim\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlbX2t0jVFGQ",
    "outputId": "a87492a1-72cb-48d8-df60-4f3aa37227cb"
   },
   "outputs": [],
   "source": [
    "print(jaccard_for_followers(273084,470294))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OgeBW2LMVFGU",
    "outputId": "6a2da56a-62a2-47d2-a416-809b9cbfa48f"
   },
   "outputs": [],
   "source": [
    "#node 1635354 not in graph \n",
    "print(jaccard_for_followees(669354,1635354))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnH2my2UVFGX"
   },
   "source": [
    "## 2.2 Cosine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNvdBGS2VFGY"
   },
   "source": [
    "\\begin{equation}\n",
    "CosineDistance = \\frac{|X\\cap Y|}{|X|\\cdot|Y|} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iznz67EdVFGZ"
   },
   "outputs": [],
   "source": [
    "#for followees\n",
    "def cosine_for_followees(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
    "                                    (math.sqrt(len(set(train_graph.successors(a)))*len((set(train_graph.successors(b))))))\n",
    "        return sim\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H55ALjkMVFGc",
    "outputId": "e63ddb7e-6216-417e-c131-c3da6713d0f5"
   },
   "outputs": [],
   "source": [
    "print(cosine_for_followees(273084,1505602))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0RGKgJFVFGf",
    "outputId": "0727e848-e72c-4ef7-fb07-5420f6f71ace"
   },
   "outputs": [],
   "source": [
    "print(cosine_for_followees(273084,1635354))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJ_yGxA0VFGj"
   },
   "outputs": [],
   "source": [
    "def cosine_for_followers(a,b):\n",
    "    try:\n",
    "        \n",
    "        if len(set(train_graph.predecessors(a))) == 0  | len(set(train_graph.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
    "                                     (math.sqrt(len(set(train_graph.predecessors(a))))*(len(set(train_graph.predecessors(b)))))\n",
    "        return sim\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75QrFJb6VFGm",
    "outputId": "818ccba9-5fc1-4040-e16e-dedce466117b"
   },
   "outputs": [],
   "source": [
    "print(cosine_for_followers(2,470294))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ut4k_F0VFGq",
    "outputId": "001450fb-ec3e-428b-8b80-d9731cea5f84"
   },
   "outputs": [],
   "source": [
    "print(cosine_for_followers(669354,1635354))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaIHhWh6VFGv"
   },
   "source": [
    "## 3. Ranking Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nfV1SprVFGx"
   },
   "source": [
    "https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html\n",
    "\n",
    "PageRank computes a ranking of the nodes in the graph G based on the structure of the incoming links.\n",
    "\n",
    "<img src='PageRanks-Example.jpg'/>\n",
    "\n",
    "Mathematical PageRanks for a simple network, expressed as percentages. (Google uses a logarithmic scale.) Page C has a higher PageRank than Page E, even though there are fewer links to C; the one link to C comes from an important page and hence is of high value. If web surfers who start on a random page have an 85% likelihood of choosing a random link from the page they are currently visiting, and a 15% likelihood of jumping to a page chosen at random from the entire web, they will reach Page E 8.1% of the time. <b>(The 15% likelihood of jumping to an arbitrary page corresponds to a damping factor of 85%.) Without damping, all web surfers would eventually end up on Pages A, B, or C, and all other pages would have PageRank zero. In the presence of damping, Page A effectively links to all pages in the web, even though it has no outgoing links of its own.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkkfYYZ6VFGy"
   },
   "source": [
    "## 3.1 Page Ranking\n",
    "\n",
    "https://en.wikipedia.org/wiki/PageRank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhPbSL1tVFG7"
   },
   "source": [
    "# 4. Other Graph Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgsorCl7VFG8"
   },
   "source": [
    "## 4.1 Shortest path:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7teH2LCVFG9"
   },
   "source": [
    "Getting Shortest path between twoo nodes, if nodes have direct path i.e directly connected then we are removing that edge and calculating path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RA076ovzVFG9"
   },
   "outputs": [],
   "source": [
    "#if has direct edge then deleting that edge and calculating shortest path\n",
    "def compute_shortest_path_length(a,b):\n",
    "    p=-1\n",
    "    try:\n",
    "        if train_graph.has_edge(a,b):\n",
    "            train_graph.remove_edge(a,b)\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "            train_graph.add_edge(a,b)\n",
    "        else:\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "        return p\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxnKId11VFG_",
    "outputId": "9f64cde1-bce8-476b-bbe0-c1805dffa928"
   },
   "outputs": [],
   "source": [
    "#testing\n",
    "compute_shortest_path_length(77697, 826021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0huWCNtRVFHC",
    "outputId": "962cd591-a1ff-4bd5-80be-99643979ed86"
   },
   "outputs": [],
   "source": [
    "#testing\n",
    "compute_shortest_path_length(669354,1635354)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baE_95bzVFHF"
   },
   "source": [
    "## 4.2 Checking for same community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "15CIQqAbVFHG",
    "outputId": "f8dc603a-f6e0-4def-c5d6-b2df16d6fcda"
   },
   "outputs": [],
   "source": [
    "#getting weekly connected edges from graph \n",
    "wcc=list(nx.weakly_connected_components(train_graph))\n",
    "def belongs_to_same_wcc(a,b):\n",
    "    index = []\n",
    "    if train_graph.has_edge(b,a):\n",
    "        return 1\n",
    "    if train_graph.has_edge(a,b):\n",
    "            for i in wcc:\n",
    "                if a in i:\n",
    "                    index= i\n",
    "                    break\n",
    "            if (b in index):\n",
    "                train_graph.remove_edge(a,b)\n",
    "                if compute_shortest_path_length(a,b)==-1:\n",
    "                    train_graph.add_edge(a,b)\n",
    "                    return 0\n",
    "                else:\n",
    "                    train_graph.add_edge(a,b)\n",
    "                    return 1\n",
    "            else:\n",
    "                return 0\n",
    "    else:\n",
    "            for i in wcc:\n",
    "                if a in i:\n",
    "                    index= i\n",
    "                    break\n",
    "            if(b in index):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "fAzOHtCFVFHI",
    "outputId": "6ad77221-2167-4572-bdbe-7070c0435b06"
   },
   "outputs": [],
   "source": [
    "belongs_to_same_wcc(861, 1659750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "HMdYpPuGVFHK",
    "outputId": "e539a146-d284-4eab-8383-e90e1b88428f"
   },
   "outputs": [],
   "source": [
    "belongs_to_same_wcc(669354,1635354)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q74nth0OVFHN"
   },
   "source": [
    "## 4.3 Adamic/Adar Index:\n",
    "Adamic/Adar measures is defined as inverted sum of degrees of common neighbours for given two vertices.\n",
    "$$A(x,y)=\\sum_{u \\in N(x) \\cap N(y)}\\frac{1}{log(|N(u)|)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CeS98LI5VFHO"
   },
   "outputs": [],
   "source": [
    "#adar index\n",
    "def calc_adar_in(a,b):\n",
    "    sum=0\n",
    "    try:\n",
    "        n=list(set(train_graph.successors(a)).intersection(set(train_graph.successors(b))))\n",
    "        if len(n)!=0:\n",
    "            for i in n:\n",
    "                sum=sum+(1/np.log10(len(list(train_graph.predecessors(i)))))\n",
    "            return sum\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KezFeRmyVFHQ",
    "outputId": "6af9a2cc-0668-4e92-d006-2248c16119cf"
   },
   "outputs": [],
   "source": [
    "calc_adar_in(1,189226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vj_m89bBVFHV",
    "outputId": "98492ae5-d45b-4f04-be6c-2287d0351005"
   },
   "outputs": [],
   "source": [
    "calc_adar_in(669354,1635354)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBUudhFAVFHY"
   },
   "source": [
    "## 4.4 Is persion was following back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_mwmopLVFHZ"
   },
   "outputs": [],
   "source": [
    "def follows_back(a,b):\n",
    "    if train_graph.has_edge(b,a):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "LdjUXIfbVFHb",
    "outputId": "e56d06bc-9900-40e9-cba0-2d04e75fdc7d"
   },
   "outputs": [],
   "source": [
    "follows_back(1,189226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmZtL65YVFHf"
   },
   "outputs": [],
   "source": [
    "follows_back(669354,1635354)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29Vrq2EXVFHi"
   },
   "source": [
    "## 4.5 Katz Centrality:\n",
    "https://en.wikipedia.org/wiki/Katz_centrality\n",
    "\n",
    "https://www.geeksforgeeks.org/katz-centrality-centrality-measure/\n",
    " Katz centrality computes the centrality for a node \n",
    "    based on the centrality of its neighbors. It is a \n",
    "    generalization of the eigenvector centrality. The\n",
    "    Katz centrality for node `i` is\n",
    " \n",
    "$$x_i = \\alpha \\sum_{j} A_{ij} x_j + \\beta,$$\n",
    "where `A` is the adjacency matrix of the graph G \n",
    "with eigenvalues $$\\lambda$$.\n",
    "\n",
    "The parameter $$\\beta$$ controls the initial centrality and \n",
    "\n",
    "$$\\alpha < \\frac{1}{\\lambda_{max}}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CN5OSqrkVFHj"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('data/fea_sample/katz.p'):\n",
    "    katz = nx.katz.katz_centrality(train_graph,alpha=0.005,beta=1)\n",
    "    pickle.dump(katz,open('data/fea_sample/katz.p','wb'))\n",
    "else:\n",
    "    katz = pickle.load(open('data/fea_sample/katz.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcU83vw7VFHm",
    "outputId": "05f49ad4-46fe-4cf6-f32a-2fe4846b0714"
   },
   "outputs": [],
   "source": [
    "print('min',katz[min(katz, key=katz.get)])\n",
    "print('max',katz[max(katz, key=katz.get)])\n",
    "print('mean',float(sum(katz.values())) / len(katz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcboIksiVFHt",
    "outputId": "99f52422-9edb-479a-d5d9-e33401160da7"
   },
   "outputs": [],
   "source": [
    "mean_katz = float(sum(katz.values())) / len(katz)\n",
    "print(mean_katz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRZqGFgYVFHx"
   },
   "source": [
    "## 4.6 Hits Score\n",
    "The HITS algorithm computes two numbers for a node. Authorities estimates the node value based on the incoming links. Hubs estimates the node value based on outgoing links.\n",
    "\n",
    "https://en.wikipedia.org/wiki/HITS_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXNHRdzUVFHz"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('data/fea_sample/hits.p'):\n",
    "    hits = nx.hits(train_graph, max_iter=100, tol=1e-08, nstart=None, normalized=True)\n",
    "    pickle.dump(hits,open('data/fea_sample/hits.p','wb'))\n",
    "else:\n",
    "    hits = pickle.load(open('data/fea_sample/hits.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PSUwSZBVVFH3",
    "outputId": "77448253-5409-4229-f0be-b8dbc14d7f46"
   },
   "outputs": [],
   "source": [
    "print('min',hits[0][min(hits[0], key=hits[0].get)])\n",
    "print('max',hits[0][max(hits[0], key=hits[0].get)])\n",
    "print('mean',float(sum(hits[0].values())) / len(hits[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZtowOLZVFH6"
   },
   "source": [
    "# 5. Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6NnRWmLVFH6"
   },
   "source": [
    "## 5. 1 Reading a sample of Data from both train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mo3zTyJEq4zt",
    "outputId": "924da377-238c-4523-abb9-e019fc9a04be"
   },
   "outputs": [],
   "source": [
    "! gdown --id 1lcxzVZ0-MkPmoH3lS35Q8rRfrecKSXb1\n",
    "! gdown --id 1_KN7S8zfHdrkRjRYOEtBxBVq8JrGxPXD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KwjJ9U21m_m"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgHje1UVVFH8"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "if os.path.isfile('train_after_eda.csv'):\n",
    "    filename = \"train_after_eda.csv\"\n",
    "    # you uncomment this line, if you dont know the lentgh of the file name\n",
    "    # here we have hardcoded the number of lines as 15100030\n",
    "    # n_train = sum(1 for line in open(filename)) #number of records in file (excludes header)\n",
    "    n_train =  15100028\n",
    "    s = 100000 #desired sample size\n",
    "    skip_train = sorted(random.sample(range(1,n_train+1),n_train-s))\n",
    "    #https://stackoverflow.com/a/22259008/4084039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOzuRFFlVFH-"
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('train_after_eda.csv'):\n",
    "    filename = \"test_after_eda.csv\"\n",
    "    # you uncomment this line, if you dont know the lentgh of the file name\n",
    "    # here we have hardcoded the number of lines as 3775008\n",
    "    # n_test = sum(1 for line in open(filename)) #number of records in file (excludes header)\n",
    "    n_test = 3775006\n",
    "    s = 50000 #desired sample size\n",
    "    skip_test = sorted(random.sample(range(1,n_test+1),n_test-s))\n",
    "    #https://stackoverflow.com/a/22259008/4084039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3D_SeUCOVFH_",
    "outputId": "3da63096-d061-4b96-aa77-62ec11b5a9b7"
   },
   "outputs": [],
   "source": [
    "print(\"Number of rows in the train data file:\", n_train)\n",
    "print(\"Number of rows we are going to elimiate in train data are\",len(skip_train))\n",
    "print(\"Number of rows in the test data file:\", n_test)\n",
    "print(\"Number of rows we are going to elimiate in test data are\",len(skip_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jNDlBAzxr-2I",
    "outputId": "08592de0-c241-4eb2-9f29-2347683364e2"
   },
   "outputs": [],
   "source": [
    "#https://drive.google.com/file/d/19mviN_yeJIfakb4kU5NfKdQlOQtaQ-kH/view?usp=sharing\n",
    "!gdown --id 19mviN_yeJIfakb4kU5NfKdQlOQtaQ-kH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HEpR_FLu2VWM",
    "outputId": "3b0a3900-120f-41c3-b217-dc6cb73df8a9"
   },
   "outputs": [],
   "source": [
    "#https://drive.google.com/file/d/1H6qybuXr8i_USWu3k3ulXEOurc-SElUh/view?usp=sharing\n",
    "!gdown --id 1H6qybuXr8i_USWu3k3ulXEOurc-SElUh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "pCisf6PpVFID",
    "outputId": "1de3fd27-e064-4850-f371-cfc649fd6a2c"
   },
   "outputs": [],
   "source": [
    "df_final_train = pd.read_csv('train_after_eda.csv', skiprows=skip_train, names=['source_node', 'destination_node'])\n",
    "df_final_train['indicator_link'] = pd.read_csv('train_y.csv', skiprows=skip_train, names=['indicator_link'])\n",
    "print(\"Our train matrix size \",df_final_train.shape)\n",
    "df_final_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "FHmdATpp3B9L",
    "outputId": "835f1ac6-6fe6-4798-83b8-d4adaf689a09"
   },
   "outputs": [],
   "source": [
    "df_final_test = pd.read_csv('test_after_eda.csv', skiprows=skip_train, names=['source_node', 'destination_node'])\n",
    "df_final_test['indicator_link'] = pd.read_csv('test_y.csv', skiprows=skip_train, names=['indicator_link'])\n",
    "print(\"Our train matrix size \",df_final_test.shape)\n",
    "df_final_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIaOWDaDVFIJ"
   },
   "source": [
    "## 5.2 Adding a set of features\n",
    "\n",
    "__we will create these each of these features for both train and test data points__\n",
    "<ol>\n",
    "<li>jaccard_followers</li>\n",
    "<li>jaccard_followees</li>\n",
    "<li>cosine_followers</li>\n",
    "<li>cosine_followees</li>\n",
    "<li>num_followers_s</li>\n",
    "<li>num_followees_s</li>\n",
    "<li>num_followers_d</li>\n",
    "<li>num_followees_d</li>\n",
    "<li>inter_followers</li>\n",
    "<li>inter_followees</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myjvdCpUqt0E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qTkOiBcVFIJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fz2eZpSnVFIL"
   },
   "outputs": [],
   "source": [
    "def compute_features_stage1(df_final):\n",
    "    #calculating no of followers followees for source and destination\n",
    "    #calculating intersection of followers and followees for source and destination\n",
    "    num_followers_s=[]\n",
    "    num_followees_s=[]\n",
    "    num_followers_d=[]\n",
    "    num_followees_d=[]\n",
    "    inter_followers=[]\n",
    "    inter_followees=[]\n",
    "    for i,row in df_final.iterrows():\n",
    "        try:\n",
    "            s1=set(train_graph.predecessors(row['source_node']))\n",
    "            s2=set(train_graph.successors(row['source_node']))\n",
    "        except:\n",
    "            s1 = set()\n",
    "            s2 = set()\n",
    "        try:\n",
    "            d1=set(train_graph.predecessors(row['destination_node']))\n",
    "            d2=set(train_graph.successors(row['destination_node']))\n",
    "        except:\n",
    "            d1 = set()\n",
    "            d2 = set()\n",
    "        num_followers_s.append(len(s1))\n",
    "        num_followees_s.append(len(s2))\n",
    "\n",
    "        num_followers_d.append(len(d1))\n",
    "        num_followees_d.append(len(d2))\n",
    "\n",
    "        inter_followers.append(len(s1.intersection(d1)))\n",
    "        inter_followees.append(len(s2.intersection(d2)))\n",
    "    \n",
    "    return  num_followers_s,num_followees_s,num_followers_d,num_followees_d,inter_followers,inter_followees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFc60kcRVFIN"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('data/fea_sample/storage_sample_stage1.h5'):\n",
    "    df_final_train['num_followers_s'], df_final_train['num_followers_d'], \\\n",
    "    df_final_train['num_followees_s'], df_final_train['num_followees_d'], \\\n",
    "    df_final_train['inter_followers'], df_final_train['inter_followees']= compute_features_stage1(df_final_train)\n",
    "    \n",
    "    df_final_test['num_followers_s'], df_final_test['num_followers_d'], \\\n",
    "    df_final_test['num_followees_s'], df_final_test['num_followees_d'], \\\n",
    "    df_final_test['inter_followers'], df_final_test['inter_followees']= compute_features_stage1(df_final_test)\n",
    "    \n",
    "    hdf = HDFStore('storage_sample_stage1.h5')\n",
    "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "    hdf.close()\n",
    "else:\n",
    "    df_final_train = read_hdf('storage_sample_stage1.h5', 'train_df',mode='r')\n",
    "    df_final_test = read_hdf('storage_sample_stage1.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "qqp2AvDRtEBN",
    "outputId": "5093df45-ecfb-41c4-b341-da5ffcfeca83"
   },
   "outputs": [],
   "source": [
    "df_final_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmlHS_b1s9U0"
   },
   "outputs": [],
   "source": [
    "a=df_final_train['num_followers_s'].values\n",
    "b=df_final_train['num_followers_d'].values\n",
    "for x,y in (zip(a,b)):\n",
    "  if x==0:\n",
    "    if y!=0:\n",
    "      print('i')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQ2K9CKg3ie9",
    "outputId": "1bb101b9-a4a2-4d22-da18-be7f9df87e7e"
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ijFg1Au3v8y",
    "outputId": "e6dd441e-ef61-4b87-f1e2-2fcf1e83357c"
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xaW2aIMC3Rhs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTXM6tQDuJNX",
    "outputId": "aa91bea5-7df2-4222-9478-de13743c845c"
   },
   "outputs": [],
   "source": [
    "# ! gdown --id 1fDJptlCFEWNV5UNGPc4geTykgFI3PDCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ieta0SZ2uYIB"
   },
   "outputs": [],
   "source": [
    "# df_final_train = read_hdf('storage_sample_stage4.h5', 'train_df',mode='r')\n",
    "# df_final_test = read_hdf('storage_sample_stage4.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "w3lzSMPnuYLO",
    "outputId": "2d190c65-0569-4cf7-a175-65ebd3b00fff"
   },
   "outputs": [],
   "source": [
    "# df_final_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfGilwI4uYNY"
   },
   "outputs": [],
   "source": [
    "# df_final_train_new=df_final_train.drop(['num_followers_s',\t'num_followees_s',\t'num_followees_d'\t,'inter_followers',\t'inter_followees'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EM_b7uEhvdN1"
   },
   "outputs": [],
   "source": [
    "# df_final_train['num_followers_d']= compute_features_stage1(df_final_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "_O8N_J5JuYPf",
    "outputId": "a08d6b41-134b-4e26-e533-9f405b351a49"
   },
   "outputs": [],
   "source": [
    "# df_final_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hAPaxMyv9LK"
   },
   "outputs": [],
   "source": [
    "# for val in df_final_train_new['num_followers_s'].values:\n",
    "#   if(val>0):\n",
    "#     print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3GrHa3a-4tAU",
    "outputId": "7f5deeae-dbd9-40ee-bad1-9d07d680da33"
   },
   "outputs": [],
   "source": [
    "# https://drive.google.com/file/d/10qJ04GRcaDxc16gmJXb8rpGPmlyys7E2/view?usp=sharing\n",
    "! gdown --id 10qJ04GRcaDxc16gmJXb8rpGPmlyys7E2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "go_e8hxxVFIO"
   },
   "source": [
    "\n",
    "## 5.3 Adding new set of features\n",
    "\n",
    "__we will create these each of these features for both train and test data points__\n",
    "<ol>\n",
    "<li>adar index</li>\n",
    "<li>is following back</li>\n",
    "<li>belongs to same weakly connect components</li>\n",
    "<li>shortest path between source and destination</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqB0Peg0VFIP"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('storage_sample_stage2.h5'):\n",
    "    #mapping adar index on train\n",
    "    df_final_train['adar_index'] = df_final_train.apply(lambda row: calc_adar_in(row['source_node'],row['destination_node']),axis=1)\n",
    "    #mapping adar index on test\n",
    "    df_final_test['adar_index'] = df_final_test.apply(lambda row: calc_adar_in(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    #mapping followback or not on train\n",
    "    df_final_train['follows_back'] = df_final_train.apply(lambda row: follows_back(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    #mapping followback or not on test\n",
    "    df_final_test['follows_back'] = df_final_test.apply(lambda row: follows_back(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    #mapping same component of wcc or not on train\n",
    "    df_final_train['same_comp'] = df_final_train.apply(lambda row: belongs_to_same_wcc(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    ##mapping same component of wcc or not on train\n",
    "    df_final_test['same_comp'] = df_final_test.apply(lambda row: belongs_to_same_wcc(row['source_node'],row['destination_node']),axis=1)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    #mapping shortest path on train \n",
    "    df_final_train['shortest_path'] = df_final_train.apply(lambda row: compute_shortest_path_length(row['source_node'],row['destination_node']),axis=1)\n",
    "    #mapping shortest path on test\n",
    "    df_final_test['shortest_path'] = df_final_test.apply(lambda row: compute_shortest_path_length(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    hdf = HDFStore('data/fea_sample/storage_sample_stage2.h5')\n",
    "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "    hdf.close()\n",
    "else:\n",
    "    df_final_train = read_hdf('storage_sample_stage2.h5', 'train_df',mode='r')\n",
    "    df_final_test = read_hdf('storage_sample_stage2.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "id": "WK4I7w8I49YO",
    "outputId": "f485518e-c720-46d6-9070-3965f14cc884"
   },
   "outputs": [],
   "source": [
    "df_final_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJ8Dbma_VFIR"
   },
   "source": [
    "## 5.4 Adding new set of features\n",
    "\n",
    "__we will create these each of these features for both train and test data points__\n",
    "<ol>\n",
    "<li>Weight Features\n",
    "    <ul>\n",
    "        <li>weight of incoming edges</li>\n",
    "        <li>weight of outgoing edges</li>\n",
    "        <li>weight of incoming edges + weight of outgoing edges</li>\n",
    "        <li>weight of incoming edges * weight of outgoing edges</li>\n",
    "        <li>2*weight of incoming edges + weight of outgoing edges</li>\n",
    "        <li>weight of incoming edges + 2*weight of outgoing edges</li>\n",
    "    </ul>\n",
    "</li>\n",
    "<li>Page Ranking of source</li>\n",
    "<li>Page Ranking of dest</li>\n",
    "<li>katz of source</li>\n",
    "<li>katz of dest</li>\n",
    "<li>hubs of source</li>\n",
    "<li>hubs of dest</li>\n",
    "<li>authorities_s of source</li>\n",
    "<li>authorities_s of dest</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVHI2jtNVFIS"
   },
   "source": [
    "#### Weight Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXmUYF9FVFIT"
   },
   "source": [
    "In order to determine the similarity of nodes, an edge weight value was calculated between nodes. Edge weight decreases as the neighbor count goes up. Intuitively, consider one million people following a celebrity on a social network then chances are most of them never met each other or the celebrity. On the other hand, if a user has 30 contacts in his/her social network, the chances are higher that many of them know each other. \n",
    "`credit` - Graph-based Features for Supervised Link Prediction\n",
    "William Cukierski, Benjamin Hamner, Bo Yang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qzbs2no7VFIV"
   },
   "source": [
    "\\begin{equation}\n",
    "W = \\frac{1}{\\sqrt{1+|X|}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkzUPrWaVFIV"
   },
   "source": [
    "it is directed graph so calculated Weighted in and Weighted out differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgNMzzTbVFIW",
    "outputId": "7e8e6d88-8bd6-45f6-f80e-82b093c18974"
   },
   "outputs": [],
   "source": [
    "#weight for source and destination of each link\n",
    "Weight_in = {}\n",
    "Weight_out = {}\n",
    "for i in  tqdm(train_graph.nodes()):\n",
    "    s1=set(train_graph.predecessors(i))\n",
    "    w_in = 1.0/(np.sqrt(1+len(s1)))\n",
    "    Weight_in[i]=w_in\n",
    "    \n",
    "    s2=set(train_graph.successors(i))\n",
    "    w_out = 1.0/(np.sqrt(1+len(s2)))\n",
    "    Weight_out[i]=w_out\n",
    "    \n",
    "#for imputing with mean\n",
    "mean_weight_in = np.mean(list(Weight_in.values()))\n",
    "mean_weight_out = np.mean(list(Weight_out.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AF4yPhIOVFIY"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('data/fea_sample/storage_sample_stage3.h5'):\n",
    "    #mapping to pandas train\n",
    "    df_final_train['weight_in'] = df_final_train.destination_node.apply(lambda x: Weight_in.get(x,mean_weight_in))\n",
    "    df_final_train['weight_out'] = df_final_train.source_node.apply(lambda x: Weight_out.get(x,mean_weight_out))\n",
    "\n",
    "    #mapping to pandas test\n",
    "    df_final_test['weight_in'] = df_final_test.destination_node.apply(lambda x: Weight_in.get(x,mean_weight_in))\n",
    "    df_final_test['weight_out'] = df_final_test.source_node.apply(lambda x: Weight_out.get(x,mean_weight_out))\n",
    "\n",
    "\n",
    "    #some features engineerings on the in and out weights\n",
    "    df_final_train['weight_f1'] = df_final_train.weight_in + df_final_train.weight_out\n",
    "    df_final_train['weight_f2'] = df_final_train.weight_in * df_final_train.weight_out\n",
    "    df_final_train['weight_f3'] = (2*df_final_train.weight_in + 1*df_final_train.weight_out)\n",
    "    df_final_train['weight_f4'] = (1*df_final_train.weight_in + 2*df_final_train.weight_out)\n",
    "\n",
    "    #some features engineerings on the in and out weights\n",
    "    df_final_test['weight_f1'] = df_final_test.weight_in + df_final_test.weight_out\n",
    "    df_final_test['weight_f2'] = df_final_test.weight_in * df_final_test.weight_out\n",
    "    df_final_test['weight_f3'] = (2*df_final_test.weight_in + 1*df_final_test.weight_out)\n",
    "    df_final_test['weight_f4'] = (1*df_final_test.weight_in + 2*df_final_test.weight_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uhxzhQ9aVFIa"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('data/fea_sample/storage_sample_stage3.h5'):\n",
    "    \n",
    "    #page rank for source and destination in Train and Test\n",
    "    #if anything not there in train graph then adding mean page rank \n",
    "    df_final_train['page_rank_s'] = df_final_train.source_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "    df_final_train['page_rank_d'] = df_final_train.destination_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "\n",
    "    df_final_test['page_rank_s'] = df_final_test.source_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "    df_final_test['page_rank_d'] = df_final_test.destination_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "    #================================================================================\n",
    "\n",
    "    #Katz centrality score for source and destination in Train and test\n",
    "    #if anything not there in train graph then adding mean katz score\n",
    "    df_final_train['katz_s'] = df_final_train.source_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "    df_final_train['katz_d'] = df_final_train.destination_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "\n",
    "    df_final_test['katz_s'] = df_final_test.source_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "    df_final_test['katz_d'] = df_final_test.destination_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "    #================================================================================\n",
    "\n",
    "    #Hits algorithm score for source and destination in Train and test\n",
    "    #if anything not there in train graph then adding 0\n",
    "    df_final_train['hubs_s'] = df_final_train.source_node.apply(lambda x: hits[0].get(x,0))\n",
    "    df_final_train['hubs_d'] = df_final_train.destination_node.apply(lambda x: hits[0].get(x,0))\n",
    "\n",
    "    df_final_test['hubs_s'] = df_final_test.source_node.apply(lambda x: hits[0].get(x,0))\n",
    "    df_final_test['hubs_d'] = df_final_test.destination_node.apply(lambda x: hits[0].get(x,0))\n",
    "    #================================================================================\n",
    "\n",
    "    #Hits algorithm score for source and destination in Train and Test\n",
    "    #if anything not there in train graph then adding 0\n",
    "    df_final_train['authorities_s'] = df_final_train.source_node.apply(lambda x: hits[1].get(x,0))\n",
    "    df_final_train['authorities_d'] = df_final_train.destination_node.apply(lambda x: hits[1].get(x,0))\n",
    "\n",
    "    df_final_test['authorities_s'] = df_final_test.source_node.apply(lambda x: hits[1].get(x,0))\n",
    "    df_final_test['authorities_d'] = df_final_test.destination_node.apply(lambda x: hits[1].get(x,0))\n",
    "    #================================================================================\n",
    "\n",
    "    hdf = HDFStore('data/fea_sample/storage_sample_stage3.h5')\n",
    "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "    hdf.close()\n",
    "else:\n",
    "    df_final_train = read_hdf('data/fea_sample/storage_sample_stage3.h5', 'train_df',mode='r')\n",
    "    df_final_test = read_hdf('data/fea_sample/storage_sample_stage3.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6xkDfD-VFIb"
   },
   "source": [
    "## 5.5 Adding new set of features\n",
    "\n",
    "__we will create these each of these features for both train and test data points__\n",
    "<ol>\n",
    "<li>SVD features for both source and destination</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQO6E65eVFIc"
   },
   "outputs": [],
   "source": [
    "def svd(x, S):\n",
    "    try:\n",
    "        z = sadj_dict[x]\n",
    "        return S[z]\n",
    "    except:\n",
    "        return [0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9sOyLwvNVFId"
   },
   "outputs": [],
   "source": [
    "#for svd features to get feature vector creating a dict node val and inedx in svd vector\n",
    "sadj_col = sorted(train_graph.nodes())\n",
    "sadj_dict = { val:idx for idx,val in enumerate(sadj_col)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLSt8fGVVFIg"
   },
   "outputs": [],
   "source": [
    "Adj = nx.adjacency_matrix(train_graph,nodelist=sorted(train_graph.nodes())).asfptype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "soq-VAHlVFIh",
    "outputId": "3f9bfb32-004f-4698-e415-469243250130"
   },
   "outputs": [],
   "source": [
    "U, s, V = svds(Adj, k = 6)\n",
    "print('Adjacency matrix Shape',Adj.shape)\n",
    "print('U Shape',U.shape)\n",
    "print('V Shape',V.shape)\n",
    "print('s Shape',s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ls5fqLFhVFIm"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('data/fea_sample/storage_sample_stage4.h5'):\n",
    "    #===================================================================================================\n",
    "    \n",
    "    df_final_train[['svd_u_s_1', 'svd_u_s_2','svd_u_s_3', 'svd_u_s_4', 'svd_u_s_5', 'svd_u_s_6']] = \\\n",
    "    df_final_train.source_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
    "    \n",
    "    df_final_train[['svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3', 'svd_u_d_4', 'svd_u_d_5','svd_u_d_6']] = \\\n",
    "    df_final_train.destination_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
    "    #===================================================================================================\n",
    "    \n",
    "    df_final_train[['svd_v_s_1','svd_v_s_2', 'svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6',]] = \\\n",
    "    df_final_train.source_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
    "\n",
    "    df_final_train[['svd_v_d_1', 'svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5','svd_v_d_6']] = \\\n",
    "    df_final_train.destination_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
    "    #===================================================================================================\n",
    "    \n",
    "    df_final_test[['svd_u_s_1', 'svd_u_s_2','svd_u_s_3', 'svd_u_s_4', 'svd_u_s_5', 'svd_u_s_6']] = \\\n",
    "    df_final_test.source_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
    "    \n",
    "    df_final_test[['svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3', 'svd_u_d_4', 'svd_u_d_5','svd_u_d_6']] = \\\n",
    "    df_final_test.destination_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
    "\n",
    "    #===================================================================================================\n",
    "    \n",
    "    df_final_test[['svd_v_s_1','svd_v_s_2', 'svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6',]] = \\\n",
    "    df_final_test.source_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
    "\n",
    "    df_final_test[['svd_v_d_1', 'svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5','svd_v_d_6']] = \\\n",
    "    df_final_test.destination_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
    "    #===================================================================================================\n",
    "\n",
    "    hdf = HDFStore('data/fea_sample/storage_sample_stage4.h5')\n",
    "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "    hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-hBtlkzVFIn"
   },
   "outputs": [],
   "source": [
    "# prepared and stored the data from machine learning models\n",
    "# pelase check the FB_Models.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "DaIHhWh6VFGv",
    "GkkfYYZ6VFGy",
    "AgsorCl7VFG8",
    "baE_95bzVFHF",
    "pBUudhFAVFHY",
    "29Vrq2EXVFHi",
    "SRZqGFgYVFHx"
   ],
   "name": "FB_featurization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
