{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac3d39d4",
   "metadata": {},
   "source": [
    "__Question-1:__\n",
    "\n",
    "__Why canâ€™t we use accuracy as a metric for an imbalanced dataset?__\n",
    "\n",
    "Imbalanced dataset is a dataset whose target feature's value counts are not approximately same or are uneven.\n",
    "\n",
    "Accuracy score is influenced by the major target class as the model is biased, hence accuracy score is not a feasible metric when we are modelling on the imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bcbcd7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487920e",
   "metadata": {},
   "source": [
    "__Question-2:__\n",
    "\n",
    "__In which scenario we will prefer recall over precision?__\n",
    "\n",
    "We prefer recall to precision, when we cannot risk having more false negatives. And we prefer precision to recall, when we cannot risk having more false positives.\n",
    "\n",
    "__What are examples from the real world where a high precision model is desirable and when a high recall model is desirable?__\n",
    "\n",
    "1. Medical Tests: It is alright to predict a healthy person as covid positive (false postive), but it is not acceptable when a covid posive patient is predicted as healthy (false negative). In this case, we need high recall model.\n",
    "\n",
    "2. Detecting Spam Calls: If a call is not dectected as spam (false negative) and is taken by customer, it is totally alright as the cutomer can mark it spam later, but if a customer does not receive a call from his/her mother as it is marked as spam (false postive) then it is not acceptable. In this case, we use high precision model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fe72f3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe35b11b",
   "metadata": {},
   "source": [
    "__Question-3:__\n",
    "\n",
    "__What are the different performance metrics that can be used for multi-class classification problems?__\n",
    "\n",
    "1. F1 score\n",
    "2. Average accuracy\n",
    "3. Log-loss\n",
    "\n",
    "__What is macro averaged precision and micro averaged precision?__\n",
    "\n",
    "Source: https://vitalflux.com/micro-average-macro-average-scoring-metrics-multi-class-classification-python/\n",
    "\n",
    "Micro averaged precision: Sum of all true positives for all classes divided by all positive predictions.\n",
    "\n",
    "Macro averaged precision: Arithmetic mean of all the precision scores of different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69120b73",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a53fdc",
   "metadata": {},
   "source": [
    "__Question-4:__\n",
    "\n",
    "__Which of the following statements is/are correct about AUC metric?__\n",
    "\n",
    "1. It tells how much the model is capable of distinguishing between classes.\n",
    "2. The AUC of a random model is 0.5.\n",
    "3. We can use AUC only for binary classification problems.\n",
    "4. Mathematically, it is the expectation that a uniformly drawn random positive is ranked before a uniformly drawn random negative.\n",
    "\n",
    "Option 1 is True.\n",
    "\n",
    "Option 2 is True.\n",
    "\n",
    "Option 3 is True.\n",
    "\n",
    "Option 4 is True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f2567",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea825d5",
   "metadata": {},
   "source": [
    "__Question-5:__\n",
    "\n",
    "__What is the most common metric used for Forecast Accuracy (Future prediction on Stock Market, Future Sale in Business)?__\n",
    "\n",
    "Source: https://towardsdatascience.com/mad-over-mape-a86a8d831447\n",
    "\n",
    "Mean Absolute Percentage Error (MAPE) is the most commom metric for forecast accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c685214",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c9b12",
   "metadata": {},
   "source": [
    "End of the file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
